{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://watanimg.elwatannews.com/old_news_images/large/249765_Large_20140709045740_11.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb../xvfb: line 24: start-stop-daemon: command not found\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1007'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1007'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'\n",
    "    \n",
    "from pyvirtualdisplay import Display\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "\n",
    "# plt.figure(figsize=(4, 3))\n",
    "# display.clear_output(wait=True)\n",
    "\n",
    "# env.reset()\n",
    "# for t in range(30):\n",
    "# #     random_action = env.action_space.sample()\n",
    "#     random_action = 0\n",
    "#     obs, _, done, _ = env.step(random_action)\n",
    "    \n",
    "#     plt.title(f'time={t}')\n",
    "#     plt.imshow(env.render('rgb_array'))\n",
    "#     display.display(plt.gcf())\n",
    "#     display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probability of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(20, 20))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit(X=[env.reset()] * n_actions, y=range(n_actions), classes=range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32),\n",
       " Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[env.observation_space] * n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([env.observation_space] * n_actions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60015151, 0.39984849])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict_proba([env.reset()]).reshape(env.action_space.n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba([s])\n",
    "        probs = probs.reshape(env.action_space.n, )\n",
    "        \n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(range(n_actions), p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[ 0.03941501  0.01106657 -0.00299715 -0.04871377]\n",
      " [ 0.03963634  0.20623137 -0.00397142 -0.34234083]\n",
      " [ 0.04376097  0.01116614 -0.01081824 -0.05091288]\n",
      " [ 0.04398429 -0.18379903 -0.0118365   0.23833726]\n",
      " [ 0.04030831 -0.3787499  -0.00706975  0.5272632 ]]\n",
      "actions: [1, 0, 0, 0, 0]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    elite_mask = rewards_batch >= reward_threshold\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    for mask, states, actions in zip(elite_mask, states_batch, actions_batch):\n",
    "        if mask:\n",
    "            elite_states += states\n",
    "            elite_actions += actions\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 191.000, threshold=215.300\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31995/1412289636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0melite_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melite_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_elites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31995/1412289636.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0melite_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melite_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_elites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31995/1741900107.py\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \"\"\"\n\u001b[1;32m   1118\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Initialize first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 721\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(env, agent) for _ in range(n_sessions)]\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "#     <YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "#     agent.partial_fit(X=[env.reset()] * n_actions, y=range(n_actions), classes=range(n_actions))\n",
    "    agent.partial_fit(X=elite_states, y=elite_actions)\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cartpole-agent.pkl', 'wb') as fout:\n",
    "    pickle.dump(agent, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    env,  Python Kernel .       ,    2  (    ,       )\n",
    "\n",
    "  a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "display.clear_output(wait=True)\n",
    "\n",
    "with open('cartpole-agent.pkl', 'rb') as fin:\n",
    "    agent = pickle.load(fin)\n",
    "\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "obs = env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "for t in range(100):\n",
    "    probs = agent.predict_proba([obs])\n",
    "    probs = probs.reshape(env.action_space.n, )\n",
    "    a = np.random.choice(range(n_actions), p=probs)\n",
    "    obs, _, done, _ = env.step(a)\n",
    "\n",
    "    plt.title(f'time={t}')\n",
    "    plt.imshow(env.render('rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ffmpeg,   ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Record sessions\n",
    "\n",
    "# import gym.wrappers\n",
    "\n",
    "# sessions2 = []\n",
    "# with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "# #     sessions = [generate_session(env_monitor, agent) for _ in range(100)]\n",
    "#     for i in range(50):\n",
    "# #         if i % 10 == 0:\n",
    "# #             print(i)\n",
    "#         print(i)\n",
    "#         sessions2.append(generate_session(env_monitor, agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show video. This may not work in some setups. If it doesn't\n",
    "# # work for you, you can download the videos and view them locally.\n",
    "# import sys\n",
    "\n",
    "# from pathlib import Path\n",
    "# from base64 import b64encode\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "# video_path = video_paths[-1]  # You can also try other indices\n",
    "\n",
    "# if 'google.colab' in sys.modules:\n",
    "#     # https://stackoverflow.com/a/57378660/1214547\n",
    "#     with video_path.open('rb') as fp:\n",
    "#         mp4 = fp.read()\n",
    "#     data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "# else:\n",
    "#     data_url = str(video_path)\n",
    "\n",
    "# HTML(\"\"\"\n",
    "# <video width=\"640\" height=\"480\" controls>\n",
    "#   <source src=\"{}\" type=\"video/mp4\">\n",
    "# </video>\n",
    "# \"\"\".format(data_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (2 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`. Provide here some figures so we can see how the hyperparameters influence the performance.\n",
    "- __1.2__ (1 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here>```\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment, you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: `MountainCar-v0` or `LunarLander-v2`.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (up to 6 pts) Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [`joblib`](https://joblib.readthedocs.io/en/latest/). However, note that you will probably need to spawn a new environment in each of the workers instead of passing it via pickling. (2 pts)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training. (2 pts)\n",
    "  * Experiment with the number of training iterations and learning rate of the neural network (see params). Provide some plots as in 1.1. (2 pts)\n",
    "  \n",
    "__Please list what you did in Anytask submission form__. \n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails to cut off bad sessions__ while R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it doesn't train, it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_mountain_car(env, agent):\n",
    "#     # Compute policy for all possible x and v (with discretization)\n",
    "#     xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "#     vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    \n",
    "#     grid = np.dstack(np.meshgrid(xs, vs[::-1])).transpose(1, 0, 2)\n",
    "#     grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "#     probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3).transpose(1, 0, 2)\n",
    "\n",
    "#     # # The above code is equivalent to the following:\n",
    "#     # probs = np.empty((len(vs), len(xs), 3))\n",
    "#     # for i, v in enumerate(vs[::-1]):\n",
    "#     #     for j, x in enumerate(xs):\n",
    "#     #         probs[i, j, :] = agent.predict_proba([[x, v]])[0]\n",
    "\n",
    "#     # Draw policy\n",
    "#     f, ax = plt.subplots(figsize=(7, 7))\n",
    "#     ax.imshow(probs, extent=(env.min_position, env.max_position, -env.max_speed, env.max_speed), aspect='auto')\n",
    "#     ax.set_title('Learned policy: red=left, green=nothing, blue=right')\n",
    "#     ax.set_xlabel('position (x)')\n",
    "#     ax.set_ylabel('velocity (v)')\n",
    "    \n",
    "#     # Sample a trajectory and draw it\n",
    "#     states, actions, _ = generate_session(env, agent)\n",
    "#     states = np.array(states)\n",
    "#     ax.plot(states[:, 0], states[:, 1], color='white')\n",
    "    \n",
    "#     # Draw every 3rd action from the trajectory\n",
    "#     for (x, v), a in zip(states[::3], actions[::3]):\n",
    "#         if a == 0:\n",
    "#             plt.arrow(x, v, -0.1, 0, color='white', head_length=0.02)\n",
    "#         elif a == 2:\n",
    "#             plt.arrow(x, v, 0.1, 0, color='white', head_length=0.02)\n",
    "\n",
    "# with gym.make('MountainCar-v0').env as env:\n",
    "#     visualize_mountain_car(env, agent_mountain_car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ (2 pts) Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in Anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ (4 pts) Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * Choose one of [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0) (90+ pts to solve), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) (200+ pts to solve) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules, aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
